{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "postal-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.policies.policy_saver import PolicySaver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tf_agents.utils import nest_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "underlying-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "# read dat file\n",
    "ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n",
    "\n",
    "# Craete DataFrame\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n",
    "ratings_df = ratings_df.astype(int).sort_values([\"UserID\", \"Timestamp\"])\n",
    "\n",
    "\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n",
    "users_df = pd.DataFrame(users_list, columns=['UserID','Gender','Age','Occupation','Zip-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historical-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "STATE_SIZE = 10\n",
    "ACTOR_LEARNIG_RATE = 0.001\n",
    "CRITIC_LEARNIG_RATE = 0.001\n",
    "\n",
    "log_interval = 25\n",
    "eval_interval  = 50\n",
    "\n",
    "NUM_EVAL_EPISODES = 10\n",
    "\n",
    "REPLAY_BUFFER_MAX_LENGTH = 50000\n",
    "NUM_EPISODE = 10000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-trader",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "smaller-kitty",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coordinated-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMovieEmbedding(tf.keras.Model):\n",
    "    def __init__(self, len_users, len_movies, embedding_dim):\n",
    "        super(UserMovieEmbedding, self).__init__()\n",
    "        self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n",
    "        # embedding\n",
    "        self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n",
    "        self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n",
    "        # dot product\n",
    "        self.m_u_merge = tf.keras.layers.Dot(name='movie_user_dot', normalize=False, axes=1)\n",
    "        # output\n",
    "        self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.m_u_input(x)\n",
    "        uemb = self.u_embedding(x[0])\n",
    "        memb = self.m_embedding(x[1])\n",
    "        m_u = self.m_u_merge([memb, uemb])\n",
    "        return self.m_u_fc(m_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "african-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num = ratings_df[\"UserID\"].max() + 1\n",
    "items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "\n",
    "embedding_network = UserMovieEmbedding(users_num, items_num, EMBEDDING_DIM)\n",
    "embedding_network([np.zeros((1,)),np.zeros((1,))])\n",
    "embedding_network.load_weights('save_weights/user_movie_embedding_case4.h5')\n",
    "\n",
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-fence",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informed-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRRAveStateRepresentation(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(DRRAveStateRepresentation, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.wav = tf.keras.layers.Conv1D(1, 1, 1)\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    def call(self, x):\n",
    "        items_eb = tf.transpose(x[1], perm=(0,2,1))/self.embedding_dim\n",
    "        wav = self.wav(items_eb)\n",
    "        wav = tf.transpose(wav, perm=(0,2,1))\n",
    "        wav = tf.squeeze(wav, axis=1)\n",
    "        user_wav = tf.keras.layers.multiply([x[0], wav])\n",
    "        concat = self.concat([x[0], user_wav, wav])\n",
    "        return self.flatten(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "smaller-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RS_Env(py_environment.PyEnvironment):\n",
    "    def __init__(self, ratings_df, embedding_dim, state_size, embedding_network):\n",
    "        self.users_num = ratings_df[\"UserID\"].max() + 1\n",
    "        self.items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "        self.ratings_df = ratings_df\n",
    "        self.pos_ratings_df = ratings_df.loc[ratings_df[\"Rating\"] >= 4]\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_network = embedding_network\n",
    "        self.state_size = state_size\n",
    "        self.max_step = 1000\n",
    "        \n",
    "            \n",
    "        self._action_spec = array_spec.BoundedArraySpec(shape = (embedding_dim, ), dtype = np.float32, maximum = 1, minimum = -1, name = \"action\")\n",
    "        self._observation_spec = array_spec.ArraySpec(shape = (3*self.embedding_dim, ), dtype = np.float32, name = \"state_representation\")\n",
    "        \n",
    "        \n",
    "        self.valid_users = self._generate_valid_user()\n",
    "        \n",
    "        # reset env\n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "    \n",
    "    def _convert_action_score_item(self, action_score):\n",
    "        items_ids = np.array(range(self.items_num))\n",
    "        \n",
    "        items_ids = np.setdiff1d(items_ids, self.recommended_items)\n",
    "        \n",
    "        items_ebs = self.embedding_network.get_layer('movie_embedding')(items_ids)\n",
    "#         action_score = tf.transpose(action_score, perm=(1,0))\n",
    "        action_score = tf.convert_to_tensor(np.expand_dims(action_score, 1))\n",
    "        \n",
    "        item_idx = np.argmax(tf.keras.backend.dot(items_ebs, action_score))\n",
    "        \n",
    "        recommendation_item = int(items_ids[item_idx])\n",
    "        \n",
    "        return recommendation_item\n",
    "        \n",
    "    \n",
    "    def _reset(self):        \n",
    "        self.step_count = 1\n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.user_df = self.ratings_df.loc[self.ratings_df[\"UserID\"] == self.user_id]\n",
    "#         self.movie_rate_dict = defaultdict(lambda: -0.5, zip(self.user_df[\"MovieID\"], self.user_df[\"Rating\"]))\n",
    "        self.state_items_ids = self.user_df.loc[self.user_df[\"Rating\"] >= 4, \"MovieID\"].head(self.state_size).values\n",
    "        self.user_items = self.user_df[\"MovieID\"].values\n",
    "        \n",
    "        self.recommended_items = self.state_items_ids.copy()\n",
    "        \n",
    "\n",
    "        self.user_eb = self.embedding_network.get_layer('user_embedding')(np.array(self.user_id))\n",
    "        state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "        \n",
    "        \n",
    "        self.srm_ave = DRRAveStateRepresentation(self.embedding_dim)\n",
    "        self._state = np.array(self.srm_ave([np.expand_dims(self.user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)])[0], dtype = np.float32)\n",
    "        \n",
    "#         for x in self.recommended_items:\n",
    "#             self.movie_rate_dict[x] = -0.5\n",
    "            \n",
    "        self._episode_ended = False\n",
    "        \n",
    "        return ts.restart(self._state)\n",
    "        \n",
    "        \n",
    "    def _generate_valid_user(self):\n",
    "        temp = self.ratings_df.loc[ratings_df[\"Rating\"] >= 4].groupby([\"UserID\"])[\"Rating\"].count()\n",
    "        valid_users = temp.loc[temp >= self.state_size].index\n",
    "        \n",
    "        return valid_users\n",
    "    \n",
    "    def _step(self, action):\n",
    "        self.step_count += 1\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return self.reset()    \n",
    "        \n",
    "        recommendation_item = self._convert_action_score_item(action)\n",
    "        self.recommendation_item = recommendation_item\n",
    "        \n",
    "        if recommendation_item in self.user_items:\n",
    "            if recommendation_item not in self.recommended_items:\n",
    "                rate = self.user_df.loc[self.user_df[\"MovieID\"] == recommendation_item, \"Rating\"].values[0]\n",
    "                reward = (rate-3)/2\n",
    "                if reward > 0:\n",
    "                    self.state_items_ids = np.append(self.state_items_ids[1:], values = recommendation_item)\n",
    "                    state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "                    self._state = np.array(self.srm_ave([np.expand_dims(self.user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)])[0], dtype = np.float32)\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = -0.5\n",
    "        \n",
    "        self.recommended_items = np.unique(np.append(self.recommended_items, recommendation_item))\n",
    "        \n",
    "        \n",
    "#         if len(self.recommended_items) >= 20:\n",
    "#             self._episode_ended = True\n",
    "        if self.step_count == self.max_step or len(np.setdiff1d(self.user_items, self.recommendation_item)) == 0:\n",
    "            self._episode_ended = True\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array(self._state), reward)\n",
    "        else:\n",
    "            return ts.transition(np.array(self._state), reward, discount = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "mounted-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_py = RS_Env(ratings_df, embedding_dim = 100, state_size = 10, embedding_network = embedding_network)\n",
    "eval_env_py = RS_Env(ratings_df, embedding_dim = 100, state_size = 10, embedding_network = embedding_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "romance-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_env_tf = tf_py_environment.TFPyEnvironment(train_env_py)\n",
    "# eval_env_tf = tf_py_environment.TFPyEnvironment(eval_env_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "equipped-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([-1.22081190e-01, -6.32757783e-01,  1.58531234e-01,  2.32574731e-01,\n",
       "       -2.24325493e-01,  4.78142023e-01,  7.40255058e-01, -2.33640313e-01,\n",
       "       -4.13052976e-01,  5.09232461e-01, -6.75686777e-01, -4.76162821e-01,\n",
       "       -9.95826900e-01, -4.58130360e-01,  1.78045198e-01, -3.52764338e-01,\n",
       "        1.17973246e-01,  5.45138240e-01, -4.43065643e-01,  8.87238264e-01,\n",
       "       -5.65481544e-01, -3.95900458e-01, -6.71227157e-01,  8.31450403e-01,\n",
       "        3.20034295e-01, -1.10320590e-01,  5.51873446e-01,  6.99094713e-01,\n",
       "        3.88916314e-01, -2.63916105e-01,  8.26793790e-01,  2.59496361e-01,\n",
       "        6.94266036e-02,  3.67458075e-01,  8.00025985e-02, -4.37568426e-01,\n",
       "       -1.02132773e+00,  6.97891176e-01, -8.18001211e-01, -2.65601017e-02,\n",
       "        3.63430351e-01, -1.35829151e-01,  1.69673815e-01, -5.92144504e-02,\n",
       "       -1.55556381e-01, -7.50934899e-01, -1.22315763e-02, -3.47645015e-01,\n",
       "       -3.12789917e-01, -1.76935524e-01, -1.80006117e-01,  3.41423243e-01,\n",
       "       -2.08345145e-01,  4.09785695e-02, -5.38267136e-01,  5.49860299e-01,\n",
       "       -7.44548962e-02,  9.56405938e-01,  2.70827055e-01, -3.12351257e-01,\n",
       "       -4.37013395e-02,  8.53807628e-02,  8.30772936e-01,  6.81524515e-01,\n",
       "       -2.91248947e-01,  6.42220497e-01,  7.24945813e-02, -3.67433846e-01,\n",
       "       -4.84072343e-02,  9.72970447e-04,  8.35455835e-01,  4.32028383e-01,\n",
       "        2.00752839e-01,  5.45905471e-01, -8.61823186e-02,  3.20109040e-01,\n",
       "        6.71090662e-01, -4.55397457e-01, -2.60267347e-01, -4.74097371e-01,\n",
       "        5.68985522e-01, -2.21176729e-01,  2.36988738e-01,  3.51337105e-01,\n",
       "        2.10910514e-01,  2.53064811e-01, -1.47056520e-01,  5.14037371e-01,\n",
       "        2.96340019e-01,  2.37362742e-01,  7.99419284e-01, -1.20126627e-01,\n",
       "        1.35076210e-01,  5.66133082e-01, -7.41650283e-01,  1.73346788e-01,\n",
       "        1.34108931e-01,  2.59395782e-02, -1.83866277e-01, -6.82084262e-01,\n",
       "        1.63266770e-04,  2.62268260e-03, -5.23768365e-04, -2.43395334e-03,\n",
       "       -1.17475132e-03, -3.48369498e-03,  1.65396254e-03,  1.97045389e-03,\n",
       "       -1.09158887e-03, -1.48202898e-03,  4.45924187e-03, -3.27497581e-03,\n",
       "        1.06233801e-03, -4.52239328e-04, -1.61533913e-04,  1.54273177e-03,\n",
       "        2.06295896e-04, -3.58991348e-03,  1.02725893e-03, -2.69801728e-03,\n",
       "        2.77081132e-03, -1.50691578e-03,  3.21101584e-03,  5.95332915e-03,\n",
       "        1.08526007e-03,  3.37507896e-04,  2.33073742e-03,  4.86325426e-03,\n",
       "        5.29664429e-03,  2.32749459e-04,  1.57320654e-04,  1.09663222e-03,\n",
       "        2.43564253e-04,  7.95256579e-04,  1.57908056e-04,  6.28620270e-04,\n",
       "        1.77407556e-03, -1.86495378e-03, -3.78188561e-04, -1.01380356e-04,\n",
       "       -1.06026675e-03,  8.23518145e-04,  9.10566712e-04,  3.09446390e-04,\n",
       "       -6.86910178e-04,  6.90148026e-03,  1.26653767e-05, -1.87486864e-03,\n",
       "        1.14545913e-03, -6.08133560e-04,  9.03152104e-04, -2.33463332e-04,\n",
       "        2.05828095e-04,  1.50968277e-04,  4.59422218e-03,  2.95520853e-03,\n",
       "        2.99897329e-05,  2.36957101e-03,  6.76054740e-04,  2.46197940e-03,\n",
       "        7.50893014e-05, -1.10954868e-04, -3.96533962e-03,  6.26948290e-03,\n",
       "        1.15542184e-03,  1.74528304e-05, -1.25816456e-04, -1.01444952e-03,\n",
       "        2.48941087e-05,  5.47843626e-07,  3.73739260e-03, -1.05138647e-03,\n",
       "        1.40377367e-03, -3.10262595e-03, -3.09343653e-04, -1.34781527e-03,\n",
       "       -8.57275154e-04,  2.14561727e-03, -2.14117975e-03,  3.99827631e-03,\n",
       "       -3.04309488e-03, -3.51386334e-05,  9.69093875e-04,  3.14507226e-04,\n",
       "       -1.08458044e-03,  5.27278578e-04, -1.88299397e-03,  1.49954704e-03,\n",
       "       -1.16828573e-03,  1.48774288e-03,  5.83849289e-03, -4.23821330e-04,\n",
       "       -1.06190599e-03,  2.02369387e-03, -1.30400155e-03,  4.66784200e-04,\n",
       "       -1.05617091e-03, -2.37481509e-04,  9.54730858e-05,  1.04920368e-03,\n",
       "       -1.33736222e-03, -4.14484460e-03, -3.30388104e-03, -1.04652531e-02,\n",
       "        5.23681613e-03, -7.28589995e-03,  2.23431434e-03, -8.43370706e-03,\n",
       "        2.64273328e-03, -2.91031925e-03, -6.59956969e-03,  6.87784888e-03,\n",
       "       -1.06678985e-03,  9.87141160e-04, -9.07263544e-04, -4.37326450e-03,\n",
       "        1.74866675e-03, -6.58532698e-03, -2.31852545e-03, -3.04091629e-03,\n",
       "       -4.89991484e-03,  3.80629953e-03, -4.78379894e-03,  7.16017373e-03,\n",
       "        3.39107425e-03, -3.05933738e-03,  4.22331877e-03,  6.95650280e-03,\n",
       "        1.36189815e-02, -8.81907006e-04,  1.90277977e-04,  4.22600238e-03,\n",
       "        3.50822648e-03,  2.16421043e-03,  1.97378662e-03, -1.43662165e-03,\n",
       "       -1.73702871e-03, -2.67227017e-03,  4.62332508e-04,  3.81701672e-03,\n",
       "       -2.91738636e-03, -6.06289692e-03,  5.36657171e-03, -5.22585958e-03,\n",
       "        4.41582780e-03, -9.19051748e-03, -1.03546563e-03,  5.39305480e-03,\n",
       "       -3.66207166e-03,  3.43703479e-03, -5.01734111e-03, -6.83794497e-04,\n",
       "       -9.87918815e-04,  3.68407881e-03, -8.53520818e-03,  5.37447166e-03,\n",
       "       -4.02790611e-04,  2.47757882e-03,  2.49625999e-03, -7.88208563e-03,\n",
       "       -1.71823800e-03, -1.29953003e-03, -4.77307243e-03,  9.19920392e-03,\n",
       "       -3.96712776e-03,  2.71757599e-05, -1.73552905e-03,  2.76090391e-03,\n",
       "       -5.14264219e-04,  5.63062960e-04,  4.47347714e-03, -2.43360503e-03,\n",
       "        6.99254731e-03, -5.68344910e-03,  3.58940987e-03, -4.21048794e-03,\n",
       "       -1.27743569e-03, -4.71152645e-03,  8.22684728e-03, -8.43345001e-03,\n",
       "       -5.34828193e-03,  1.58871291e-04,  4.08919808e-03,  8.95172241e-04,\n",
       "       -5.14237257e-03,  2.08357139e-03,  1.28045594e-02,  2.91719451e-03,\n",
       "       -3.94238252e-03,  6.26780279e-03,  7.30341766e-03,  3.52812139e-03,\n",
       "       -7.86153227e-03,  3.57459020e-03,  1.75824319e-03,  2.69277673e-03,\n",
       "       -7.87547044e-03, -9.15518031e-03, -5.19252848e-04, -1.53823185e-03],\n",
       "      dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_py.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-dress",
   "metadata": {},
   "source": [
    "### Actor Networktrain_env_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "together-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pleased-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(100,), dtype=dtype('float32'), name='action', minimum=-1.0, maximum=1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env_py.action_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_py.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "isolated-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_action_spec = tf.nest.flatten( train_env_py.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "chronic-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedArraySpec(shape=(100,), dtype=dtype('float32'), name='action', minimum=-1.0, maximum=1.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_action_spec[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "proof-fever",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'tf.float32' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-2d554d3ed868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflat_action_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'tf.float32' as a data type"
     ]
    }
   ],
   "source": [
    "flat_action_spec[0].dtype == tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "theoretical-oxford",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'tf.float32' as a data type\n  In call to configurable 'ActorNetwork' (<class 'tf_agents.agents.ddpg.actor_network.ActorNetwork'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-eca1fceb5831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m actor_net  = tf_agents.agents.ddpg.actor_network.ActorNetwork(input_tensor_spec = train_env_py.observation_spec(), \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                               \u001b[0moutput_tensor_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_env_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# --> Only float actions are supported by this network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                               \u001b[0mfc_layer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                               \u001b[0mactivation_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                               name = \"ActorNetwork\")\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m_capture_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;31m# Avoid auto tracking which prevents keras from tracking layers that are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0;31m# passed as kwargs to the Network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/agents/ddpg/actor_network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_tensor_spec, output_tensor_spec, fc_layer_params, dropout_layer_params, conv_layer_params, activation_fn, kernel_initializer, last_kernel_initializer, name)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_action_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_action_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_action_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Only float actions are supported by this network.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'tf.float32' as a data type\n  In call to configurable 'ActorNetwork' (<class 'tf_agents.agents.ddpg.actor_network.ActorNetwork'>)"
     ]
    }
   ],
   "source": [
    "actor_net  = tf_agents.agents.ddpg.actor_network.ActorNetwork(input_tensor_spec = train_env_py.observation_spec(), \n",
    "                                                              output_tensor_spec = train_env_py.action_spec(),\n",
    "                                                              fc_layer_params=[128, 128],\n",
    "                                                              activation_fn = tf.nn.relu,\n",
    "                                                              name = \"ActorNetwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "republican-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"ActorNetwork2323\")\n",
    "\n",
    "# target_actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"TargetActorNetwork2323\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-banner",
   "metadata": {},
   "source": [
    "### Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proper-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_net = tf_agents.agents.ddpg.critic_network.CriticNetwork(\n",
    "    input_tensor_spec = (train_env_py.observation_spec(), train_env_py.action_spec()),\n",
    "    observation_fc_layer_params = [100],\n",
    "    joint_fc_layer_params = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    output_activation_fn = tf.nn.relu,\n",
    "    name='CriticNetwork'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sunrise-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTOR_LEARNIG_RATE = 0.001\n",
    "# CRITIC_LEARNIG_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-plant",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instrumental-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.train.utils import train_utils\n",
    "train_step = train_utils.create_train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "liquid-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ddpg_agent = tf_agents.agents.DdpgAgent(time_step_spec = train_env_tf.time_step_spec(),\n",
    "                                           action_spec = train_env_tf.action_spec(),\n",
    "                                           actor_network = actor_net,\n",
    "                                           critic_network = critic_net,\n",
    "                                           actor_optimizer = tf.keras.optimizers.Adam(learning_rate=ACTOR_LEARNIG_RATE),\n",
    "                                           critic_optimizer = tf.keras.optimizers.Adam(learning_rate=CRITIC_LEARNIG_RATE),\n",
    "#                                            target_actor_network = target_actor_net,\n",
    "#                                            target_critic_network = target_critic_net,\n",
    "                                           target_update_tau = 0.001,\n",
    "                                           target_update_period = 1,\n",
    "                                           gamma = 0.9,\n",
    "                                           ou_stddev=0.5,\n",
    "                                           ou_damping=0.15,\n",
    "                                           train_step_counter = train_step\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "civic-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ddpg_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "vocational-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY_BUFFER_MAX_LENGTH = 50000\n",
    "# NUM_EPISODE = 10000\n",
    "# BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "interracial-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: Could not serialize policy.distribution() for policy \"<tf_agents.policies.ou_noise_policy.OUNoisePolicy object at 0x7f9083aa67f0>\". Calling saved_model.distribution() will raise the following assertion error: Distributions are not implemented yet.\n"
     ]
    }
   ],
   "source": [
    "my_policy = tf_ddpg_agent.collect_policy\n",
    "saver = PolicySaver(my_policy, batch_size = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-multimedia",
   "metadata": {},
   "source": [
    "### Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "separated-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EVAL_EPISODES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "perceived-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civilian-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-garage",
   "metadata": {},
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chief-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPLAY_BUFFER_MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "integral-belief",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(data_spec = tf_ddpg_agent.collect_data_spec,\n",
    "                                                               batch_size = train_env_tf.batch_size,\n",
    "                                                               max_length = REPLAY_BUFFER_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adverse-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:382: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = replay_buffer.as_dataset(num_parallel_calls=3, \n",
    "                                   sample_batch_size = BATCH_SIZE, \n",
    "                                   num_steps=2).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-belle",
   "metadata": {},
   "source": [
    "### Reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "buried-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "increased-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "identified-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indian-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'PER_table'\n",
    "table = reverb.Table(table_name,               \n",
    "                     max_size=REPLAY_BUFFER_MAX_LENGTH,\n",
    "                     sampler=reverb.selectors.Prioritized(0.8),\n",
    "                     remover=reverb.selectors.Fifo(),\n",
    "                     rate_limiter=reverb.rate_limiters.MinSize(100))\n",
    "\n",
    "reverb_server = reverb.Server([table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wireless-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(tf_ddpg_agent.collect_data_spec,\n",
    "                                                        sequence_length=2,\n",
    "                                                        table_name=table_name,\n",
    "                                                        local_server=reverb_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tender-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reverb_replay.as_dataset(\n",
    "      sample_batch_size=BATCH_SIZE, num_steps=2).prefetch(4)\n",
    "# experience_dataset_fn = lambda: dataset\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-projector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "endangered-definition",
   "metadata": {},
   "source": [
    "### Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unexpected-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies import py_tf_eager_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-macintosh",
   "metadata": {},
   "source": [
    "##### agent.policy : 평가 및 배포에 사용되는 기본 정책 (Noise X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "medium-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_eval_policy = tf_ddpg_agent.policy\n",
    "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(tf_eval_policy, use_tf_function=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-quarter",
   "metadata": {},
   "source": [
    "##### agent.collect_policy : 데이터 수집에 사용되는 정책 (Noise O) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "honest-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_collect_policy = tf_ddpg_agent.collect_policy\n",
    "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(tf_collect_policy, use_tf_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-national",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "boring-princess",
   "metadata": {},
   "source": [
    "### Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "genuine-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.train import actor\n",
    "from tf_agents.train import learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "heard-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(reverb_replay.py_client,\n",
    "                                                       table_name,\n",
    "                                                       sequence_length=2,\n",
    "                                                       stride_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "selected-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = \"summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dried-playing",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Actor doesn't support TFEnvironments yet.\n  In call to configurable 'Actor' (<class 'tf_agents.train.actor.Actor'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-91ddd140dd4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv_step_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvironmentSteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m collect_actor = actor.Actor(train_env_tf,\n\u001b[0m\u001b[1;32m      3\u001b[0m                             \u001b[0mcollect_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0msteps_per_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/train/actor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, policy, train_step, steps_per_run, episodes_per_run, observers, metrics, reference_metrics, summary_dir, summary_interval, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m           max_episodes=episodes_per_run)\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFEnvironment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actor doesn't support TFEnvironments yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown environment type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Actor doesn't support TFEnvironments yet.\n  In call to configurable 'Actor' (<class 'tf_agents.train.actor.Actor'>)"
     ]
    }
   ],
   "source": [
    "# actor doesn't support TFEnvironments yet.?????????????????????????????????????????????????????????????\n",
    "env_step_metric = py_metrics.EnvironmentSteps()\n",
    "collect_actor = actor.Actor(train_env_tf,\n",
    "                            collect_policy,\n",
    "                            train_step,\n",
    "                            steps_per_run=1,\n",
    "                            metrics=actor.collect_metrics(10),\n",
    "                            summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),\n",
    "                            observers=[rb_observer, env_step_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-belarus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-capitol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intended-analysis",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "modular-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_episode(environment, policy, num_episodes):\n",
    "\n",
    "    episode_counter = 0\n",
    "    traj_counter = 0\n",
    "    environment.reset()\n",
    "#     print(episode_counter)\n",
    "    while episode_counter < num_episodes:\n",
    "        time_step = environment.current_time_step()\n",
    "        action_step = policy.action(time_step)\n",
    "        next_time_step = environment.step(action_step.action)\n",
    "        traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "        traj_counter += 1\n",
    "        # Add trajectory to the replay buffer\n",
    "        reverb_replay.add_batch(traj)           \n",
    "\n",
    "        if traj.is_boundary():\n",
    "            episode_counter += 1\n",
    "    return traj_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "opposed-tribune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_ddpg_agent.train = common.function(tf_ddpg_agent.train)\n",
    "tf_ddpg_agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "equipped-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)\n",
    "returns = [avg_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(NUM_EPISODE)):\n",
    "    collect_episode(train_env_tf, tf_ddpg_agent.collect_policy, 1)\n",
    "    \n",
    "#     experience = replay_buffer.as_dataset()\n",
    "    experience, unused_info = next(iterator)\n",
    "#     experience = replay_buffer.gather_all()\n",
    "    train_loss = tf_ddpg_agent.train(experience)\n",
    "#     replay_buffer.clear()\n",
    "\n",
    "    step = tf_ddpg_agent.train_step_counter.numpy()\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-miller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4796,
   "id": "digital-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
