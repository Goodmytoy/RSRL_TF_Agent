{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4533,
   "id": "oriented-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.specs import tensor_spec\n",
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tf_agents.utils import nest_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seventh-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parental-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "# read dat file\n",
    "ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n",
    "\n",
    "# Craete DataFrame\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n",
    "users_df = pd.DataFrame(users_list, columns=['UserID','Gender','Age','Occupation','Zip-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-margin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3701,
   "id": "meaning-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "STATE_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-verification",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3918,
   "id": "becoming-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num = ratings_df[\"UserID\"].max() + 1\n",
    "items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "\n",
    "embedding_network = UserMovieEmbedding(users_num, items_num, EMBEDDING_DIM)\n",
    "embedding_network([np.zeros((1,)),np.zeros((1,))])\n",
    "embedding_network.load_weights('save_weights/user_movie_embedding_case4.h5')\n",
    "\n",
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-cream",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3919,
   "id": "functional-customer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMovieEmbedding(tf.keras.Model):\n",
    "    def __init__(self, len_users, len_movies, embedding_dim):\n",
    "        super(UserMovieEmbedding, self).__init__()\n",
    "        self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n",
    "        # embedding\n",
    "        self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n",
    "        self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n",
    "        # dot product\n",
    "        self.m_u_merge = tf.keras.layers.Dot(name='movie_user_dot', normalize=False, axes=1)\n",
    "        # output\n",
    "        self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.m_u_input(x)\n",
    "        uemb = self.u_embedding(x[0])\n",
    "        memb = self.m_embedding(x[1])\n",
    "        m_u = self.m_u_merge([memb, uemb])\n",
    "        return self.m_u_fc(m_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3920,
   "id": "fantastic-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRRAveStateRepresentation(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(DRRAveStateRepresentation, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.wav = tf.keras.layers.Conv1D(1, 1, 1)\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    def call(self, x):\n",
    "        items_eb = tf.transpose(x[1], perm=(0,2,1))/self.embedding_dim\n",
    "        wav = self.wav(items_eb)\n",
    "        wav = tf.transpose(wav, perm=(0,2,1))\n",
    "        wav = tf.squeeze(wav, axis=1)\n",
    "        user_wav = tf.keras.layers.multiply([x[0], wav])\n",
    "        concat = self.concat([x[0], user_wav, wav])\n",
    "        return self.flatten(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4663,
   "id": "literary-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RS_Env(py_environment.PyEnvironment):\n",
    "    def __init__(self, ratings_df, embedding_dim, state_size, embedding_network):\n",
    "        self.users_num = ratings_df[\"UserID\"].max() + 1\n",
    "        self.items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "        self.ratings_df = ratings_df\n",
    "        self.pos_ratings_df = ratings_df.loc[ratings_df[\"Rating\"] >= 4]\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_network = embedding_network\n",
    "        self.state_size = state_size\n",
    "        \n",
    "            \n",
    "        self._action_spec = array_spec.ArraySpec(shape = (1, ), dtype = np.int64, name = \"action\")\n",
    "        self._observation_spec = array_spec.ArraySpec(shape = (1,3*self.embedding_dim, ), dtype = np.float32, name = \"state_representation\")\n",
    "        \n",
    "        \n",
    "        self.valid_users = self._generate_valid_user()\n",
    "        \n",
    "        # reset env\n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.user_df = self.ratings_df.loc[self.ratings_df[\"UserID\"] == self.user_id]\n",
    "        self.movie_rate_dict = defaultdict(lambda: -0.5, zip(self.user_df[\"MovieID\"], self.user_df[\"Rating\"]))\n",
    "        self.state_items_ids = self.user_df.loc[self.user_df[\"Rating\"] >= 4, \"MovieID\"].head(self.state_size).values\n",
    "        self.user_items = self.user_df[\"MovieID\"].values\n",
    "        \n",
    "        self.recommended_items = self.state_items_ids.copy()\n",
    "        \n",
    "\n",
    "        user_eb = self.embedding_network.get_layer('user_embedding')(np.array(self.user_id))\n",
    "        state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "        \n",
    "        \n",
    "        self.srm_ave = DRRAveStateRepresentation(self.embedding_dim)\n",
    "        self._state = np.array(self.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)]))\n",
    "        \n",
    "        for x in self.recommended_items:\n",
    "            self.movie_rate_dict[x] = -0.5\n",
    "            \n",
    "        self._episode_ended = False\n",
    "        \n",
    "        \n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "    \n",
    "    def _reset(self):        \n",
    "        \n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.user_df = self.ratings_df.loc[self.ratings_df[\"UserID\"] == self.user_id]\n",
    "        self.movie_rate_dict = defaultdict(lambda: -0.5, zip(self.user_df[\"MovieID\"], self.user_df[\"Rating\"]))\n",
    "        self.state_items_ids = self.user_df.loc[self.user_df[\"Rating\"] >= 4, \"MovieID\"].head(self.state_size).values\n",
    "        self.user_items = self.user_df[\"MovieID\"].values\n",
    "        \n",
    "        self.recommended_items = self.state_items_ids.copy()\n",
    "        \n",
    "\n",
    "        user_eb = self.embedding_network.get_layer('user_embedding')(np.array(self.user_id))\n",
    "        state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "        \n",
    "        \n",
    "        self.srm_ave = DRRAveStateRepresentation(self.embedding_dim)\n",
    "        self._state = np.array(self.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)]))\n",
    "        \n",
    "        for x in self.recommended_items:\n",
    "            self.movie_rate_dict[x] = -0.5\n",
    "            \n",
    "        self._episode_ended = False\n",
    "        \n",
    "        return ts.restart(self._state)\n",
    "        \n",
    "        \n",
    "    def _generate_valid_user(self):\n",
    "        temp = self.ratings_df.loc[ratings_df[\"Rating\"] >= 4].groupby([\"UserID\"])[\"Rating\"].count()\n",
    "        valid_users = temp.loc[temp >= self.state_size].index\n",
    "        \n",
    "        return valid_users\n",
    "    \n",
    "    def _step(self, action):\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return self.reset()    \n",
    "        \n",
    "        \n",
    "        if action in self.user_items:\n",
    "            if action not in self.recommended_items:\n",
    "                rate = self.user_df.loc[self.user_df[\"MovieID\"] == action, \"Rating\"].values\n",
    "                reward = (rate-3)/2\n",
    "                if reward > 0:\n",
    "                    self.state_items_ids = np.append(self.state_items_ids[1:], values = action)\n",
    "                    state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "                    self._state = self.srm_ave([np.expand_dims(user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)])\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = -0.5\n",
    "        \n",
    "        self.recommended_items = np.unique(np.append(self.recommended_items, action))\n",
    "        \n",
    "        \n",
    "        if len(self.recommended_items) > 20:\n",
    "            self._episode_ended = True\n",
    "            \n",
    "        if self._episode_ended:\n",
    "            return ts.termination(self._state, reward)\n",
    "        else:\n",
    "            return ts.transition(self._state, reward, discount = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4666,
   "id": "blond-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_env = RS_Env(ratings_df, embedding_dim = 100, state_size = 10, embedding_network = embedding_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4667,
   "id": "heavy-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rs_env = tf_py_environment.TFPyEnvironment(rs_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-academy",
   "metadata": {},
   "source": [
    "### Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4615,
   "id": "raised-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4616,
   "id": "nervous-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_net  = tf_agents.agents.ddpg.actor_network.ActorNetwork(\n",
    "#     input_tensor_spec = tf_rs_env.observation_spec(), \n",
    "#     output_tensor_spec = tf_rs_env.action_spec(),  # --> Only float actions are supported by this network.\n",
    "#     fc_layer_params=[128, 128, 100],\n",
    "#     activation_fn = tf.nn.relu,\n",
    "#     name = \"ActorNetwork\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4617,
   "id": "talented-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4682,
   "id": "endangered-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(network.Network):\n",
    "    def __init__(self, \n",
    "                 observation_spec,\n",
    "                 action_spec,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 items_num,\n",
    "                 movie_embedding,\n",
    "                 name):\n",
    "        \n",
    "        super(ActorNetwork, self).__init__(input_tensor_spec=observation_spec, state_spec=(), name=name)\n",
    "        \n",
    "        self.movie_embedding = movie_embedding\n",
    "        self.items_num = items_num\n",
    "        self._action_spec = action_spec\n",
    "#         self._network_output_spec = None\n",
    "        self.observation_spec = observation_spec\n",
    "        \n",
    "#         self.model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.InputLayer(name='input_layer', input_shape=(3*embedding_dim,)),\n",
    "#             tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "#             tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "#             tf.keras.layers.Dense(embedding_dim, activation='tanh')\n",
    "#         ])\n",
    "\n",
    "        self.model = tf_agents.networks.Sequential([tf.keras.layers.InputLayer(name='input_layer', input_shape=(3*embedding_dim,)),\n",
    "                                                    tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "                                                    tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "                                                    tf.keras.layers.Dense(embedding_dim, activation='tanh')\n",
    "                                                   ])\n",
    "                                                   \n",
    "        \n",
    "        \n",
    "        self.recommended_items = []\n",
    "    \n",
    "    def create_variables(self, input_tensor_spec=None, **kwargs):\n",
    "        \"\"\"Force creation of the network's variables.\n",
    "        Return output specs.\n",
    "        Args:\n",
    "          input_tensor_spec: (Optional).  Override or provide an input tensor spec\n",
    "            when creating variables.\n",
    "          **kwargs: Other arguments to `network.call()`, e.g. `training=True`.\n",
    "        Returns:\n",
    "          Output specs - a nested spec calculated from the outputs (excluding any\n",
    "          batch dimensions).  If any of the output elements is a tfp `Distribution`,\n",
    "          the associated spec entry returned is `None`.\n",
    "        Raises:\n",
    "          ValueError: If no `input_tensor_spec` is provided, and the network did\n",
    "            not provide one during construction.\n",
    "        \"\"\"\n",
    "        if self._network_output_spec is not None:\n",
    "            if self._network_output_spec.shape != []:\n",
    "                print(f\"_network_output_spec : {self._network_output_spec}\")\n",
    "                return self._network_output_spec\n",
    "    \n",
    "        if self._input_tensor_spec is None:\n",
    "            print(f\"_input_tensor_spec : {self._input_tensor_spec}\")\n",
    "            self._input_tensor_spec = input_tensor_spec\n",
    "        input_tensor_spec = self._input_tensor_spec\n",
    "        \n",
    "        if input_tensor_spec is None:\n",
    "            raise ValueError(\n",
    "              \"Unable to create_variables: no input_tensor_spec provided, and \"\n",
    "              \"Network did not define one.\")\n",
    "\n",
    "        random_input = tensor_spec.sample_spec_nest(\n",
    "            input_tensor_spec, outer_dims=(1,))\n",
    "        \n",
    "        initial_state = self.get_initial_state(batch_size=1)\n",
    "        step_type = tf.fill((1,), time_step.StepType.FIRST)\n",
    "        outputs = self.__call__(\n",
    "                    random_input,\n",
    "                    step_type=step_type,\n",
    "                    network_state=initial_state,\n",
    "                    **kwargs)\n",
    "        print(outputs)\n",
    "        \n",
    "#         def _calc_unbatched_spec(x):\n",
    "#             if isinstance(x, tfp.distributions.Distribution):\n",
    "#                 parameters = distribution_utils.get_parameters(x)\n",
    "#                 parameter_specs = _convert_to_spec_and_remove_singleton_batch_dim(parameters, outer_ndim=1)\n",
    "\n",
    "#                 return distribution_utils.DistributionSpecV2(event_shape=x.event_shape, dtype=x.dtype, parameters=parameter_specs)\n",
    "#             else:\n",
    "#                 return nest_utils.remove_singleton_batch_spec_dim(tf.type_spec_from_value(x), outer_ndim=1)\n",
    "\n",
    "#         self._network_output_spec = tf.nest.map_structure(_calc_unbatched_spec, outputs[0])\n",
    "\n",
    "        self._network_output_spec = tf.type_spec_from_value(outputs[0])\n",
    "        return self._network_output_spec        \n",
    "    \n",
    "    \n",
    "    def call(self, observations, step_type = (), network_state = ()):\n",
    "        action_score, network_state = self.model(observations)\n",
    "        action_score = tf.reshape(action_score, (1,100))\n",
    "        \n",
    "        items_ids = np.array(range(self.items_num))\n",
    "        \n",
    "#         items_ebs = self.embedding_network.get_layer('movie_embedding')(items_ids)\n",
    "        items_ebs = self.movie_embedding\n",
    "        action_score = tf.transpose(action_score, perm=(1,0))\n",
    "        \n",
    "        item_idx = np.argmax(tf.keras.backend.dot(items_ebs, action_score))\n",
    "        \n",
    "        action = int(items_ids[item_idx])\n",
    "        self.recommended_items.append(action)\n",
    "        \n",
    "        return tf.nest.pack_sequence_as(self._action_spec, [tf.convert_to_tensor(np.array([action]))]), network_state \n",
    "#         return tf.convert_to_tensor(np.array([action])), network_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4683,
   "id": "governing-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"ActorNetwork2323\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4684,
   "id": "animal-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"TargetActorNetwork2323\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-start",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4685,
   "id": "valued-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_net = tf_agents.agents.ddpg.critic_network.CriticNetwork(\n",
    "    input_tensor_spec = (tf_rs_env.observation_spec(), tf_rs_env.action_spec()),\n",
    "    observation_fc_layer_params = [100],\n",
    "    joint_fc_layer_params = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    output_activation_fn = tf.nn.relu,\n",
    "    name='CriticNetwork'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4686,
   "id": "found-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_critic_net = tf_agents.agents.ddpg.critic_network.CriticNetwork(\n",
    "    input_tensor_spec = (tf_rs_env.observation_spec(), tf_rs_env.action_spec()),\n",
    "    observation_fc_layer_params = [100],\n",
    "    joint_fc_layer_params = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    output_activation_fn = tf.nn.relu,\n",
    "    name='TargetCriticNetwork'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4687,
   "id": "supreme-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTOR_LEARNIG_RATE = 0.001\n",
    "CRITIC_LEARNIG_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4689,
   "id": "typical-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_network_output_spec : TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "(<tf.Tensor: shape=(1,), dtype=int64, numpy=array([2657])>, ())\n",
      "_network_output_spec : TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n",
      "_network_output_spec : TensorSpec(shape=(1,), dtype=tf.int64, name=None)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "OU Noise is applicable only to continuous actions.\n  In call to configurable 'DdpgAgent' (<class 'tf_agents.agents.ddpg.ddpg_agent.DdpgAgent'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4689-db3ae0b767c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tf_ddpg_agent = tf_agents.agents.DdpgAgent(time_step_spec = tf_rs_env.time_step_spec(),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                            \u001b[0maction_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_rs_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                            \u001b[0mactor_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                            \u001b[0mcritic_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            \u001b[0mactor_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mACTOR_LEARNIG_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/agents/ddpg/ddpg_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, time_step_spec, action_spec, actor_network, critic_network, actor_optimizer, critic_optimizer, ou_stddev, ou_damping, target_actor_network, target_critic_network, target_update_tau, target_update_period, dqda_clipping, td_errors_loss_fn, gamma, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtime_step_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         actor_network=self._actor_network, clip=False)\n\u001b[0;32m--> 177\u001b[0;31m     collect_policy = ou_noise_policy.OUNoisePolicy(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mcollect_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mou_stddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ou_stddev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/policies/ou_noise_policy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wrapped_policy, ou_stddev, ou_damping, clip, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OU Noise is applicable only to continuous actions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_validate_action_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     super(OUNoisePolicy, self).__init__(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/policies/ou_noise_policy.py\u001b[0m in \u001b[0;36m_validate_action_spec\u001b[0;34m(action_spec)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_action_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OU Noise is applicable only to continuous actions.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_validate_action_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: OU Noise is applicable only to continuous actions.\n  In call to configurable 'DdpgAgent' (<class 'tf_agents.agents.ddpg.ddpg_agent.DdpgAgent'>)"
     ]
    }
   ],
   "source": [
    "tf_ddpg_agent = tf_agents.agents.DdpgAgent(time_step_spec = tf_rs_env.time_step_spec(),\n",
    "                                           action_spec = tf_rs_env.action_spec(),\n",
    "                                           actor_network = actor_net,\n",
    "                                           critic_network = critic_net,\n",
    "                                           actor_optimizer = tf.keras.optimizers.Adam(learning_rate=ACTOR_LEARNIG_RATE),\n",
    "                                           critic_optimizer = tf.keras.optimizers.Adam(learning_rate=CRITIC_LEARNIG_RATE),\n",
    "#                                            target_actor_network = target_actor_net,\n",
    "#                                            target_critic_network = target_critic_net,\n",
    "                                           target_update_tau = 0.001,\n",
    "                                           target_update_period = 1,\n",
    "                                           gamma = 0.9\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver(tf_ddpg_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-cornell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-valentine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-animation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
