{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "emotional-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_agents\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.policies.policy_saver import PolicySaver\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tf_agents.utils import nest_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "handy-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "three-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(os.path.join(DATA_DIR,'valid_ratings_df_train.csv'))\n",
    "test_ratings_df = pd.read_csv(os.path.join(DATA_DIR,'valid_ratings_df_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comparable-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading datasets\n",
    "# read dat file\n",
    "ratings_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'ratings.dat'), 'r').readlines()]\n",
    "users_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'users.dat'), 'r').readlines()]\n",
    "movies_list = [i.strip().split(\"::\") for i in open(os.path.join(DATA_DIR,'movies.dat'),encoding='latin-1').readlines()]\n",
    "\n",
    "# Craete DataFrame\n",
    "ratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = np.uint32)\n",
    "ratings_df = ratings_df.astype(int).sort_values([\"UserID\", \"Timestamp\"])\n",
    "\n",
    "\n",
    "movies_df = pd.DataFrame(movies_list, columns = ['MovieID', 'Title', 'Genres'])\n",
    "movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)\n",
    "users_df = pd.DataFrame(users_list, columns=['UserID','Gender','Age','Occupation','Zip-code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "patent-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "STATE_SIZE = 10\n",
    "ACTOR_LEARNIG_RATE = 0.001\n",
    "CRITIC_LEARNIG_RATE = 0.001\n",
    "\n",
    "log_interval = 25\n",
    "eval_interval  = 50\n",
    "\n",
    "NUM_EVAL_EPISODES = 10\n",
    "\n",
    "REPLAY_BUFFER_MAX_LENGTH = 50000\n",
    "NUM_EPISODE = 10000\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "skilled-inclusion",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "focused-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserMovieEmbedding(tf.keras.Model):\n",
    "    def __init__(self, len_users, len_movies, embedding_dim):\n",
    "        super(UserMovieEmbedding, self).__init__()\n",
    "        self.m_u_input = tf.keras.layers.InputLayer(name='input_layer', input_shape=(2,))\n",
    "        # embedding\n",
    "        self.u_embedding = tf.keras.layers.Embedding(name='user_embedding', input_dim=len_users, output_dim=embedding_dim)\n",
    "        self.m_embedding = tf.keras.layers.Embedding(name='movie_embedding', input_dim=len_movies, output_dim=embedding_dim)\n",
    "        # dot product\n",
    "        self.m_u_merge = tf.keras.layers.Dot(name='movie_user_dot', normalize=False, axes=1)\n",
    "        # output\n",
    "        self.m_u_fc = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.m_u_input(x)\n",
    "        uemb = self.u_embedding(x[0])\n",
    "        memb = self.m_embedding(x[1])\n",
    "        m_u = self.m_u_merge([memb, uemb])\n",
    "        return self.m_u_fc(m_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_num = ratings_df[\"UserID\"].max() + 1\n",
    "items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "\n",
    "embedding_network = UserMovieEmbedding(users_num, items_num, EMBEDDING_DIM)\n",
    "embedding_network([np.zeros((1,)),np.zeros((1,))])\n",
    "embedding_network.load_weights('save_weights/user_movie_embedding_case4.h5')\n",
    "\n",
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-integration",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "close-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRRAveStateRepresentation(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(DRRAveStateRepresentation, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.wav = tf.keras.layers.Conv1D(1, 1, 1)\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    def call(self, x):\n",
    "        items_eb = tf.transpose(x[1], perm=(0,2,1))/self.embedding_dim\n",
    "        wav = self.wav(items_eb)\n",
    "        wav = tf.transpose(wav, perm=(0,2,1))\n",
    "        wav = tf.squeeze(wav, axis=1)\n",
    "        user_wav = tf.keras.layers.multiply([x[0], wav])\n",
    "        concat = self.concat([x[0], user_wav, wav])\n",
    "        return self.flatten(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "great-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RS_Env(py_environment.PyEnvironment):\n",
    "    def __init__(self, ratings_df, embedding_dim, state_size, embedding_network):\n",
    "        self.users_num = ratings_df[\"UserID\"].max() + 1\n",
    "        self.items_num = ratings_df[\"MovieID\"].max() + 1\n",
    "        self.ratings_df = ratings_df\n",
    "        self.pos_ratings_df = ratings_df.loc[ratings_df[\"Rating\"] >= 4]\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_network = embedding_network\n",
    "        self.state_size = state_size\n",
    "        self.max_step = 1000\n",
    "        \n",
    "            \n",
    "        self._action_spec = array_spec.BoundedArraySpec(shape = (embedding_dim, ), dtype = np.float32, maximum = 1, minimum = -1, name = \"action\")\n",
    "        self._observation_spec = array_spec.ArraySpec(shape = (3*self.embedding_dim, ), dtype = np.float32, name = \"state_representation\")\n",
    "        \n",
    "        \n",
    "        self.valid_users = self._generate_valid_user()\n",
    "        \n",
    "        # reset env\n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "    \n",
    "    def _convert_action_score_item(self, action_score):\n",
    "        items_ids = np.array(range(self.items_num))\n",
    "        \n",
    "        items_ids = np.setdiff1d(items_ids, self.recommended_items)\n",
    "        \n",
    "        items_ebs = self.embedding_network.get_layer('movie_embedding')(items_ids)\n",
    "#         action_score = tf.transpose(action_score, perm=(1,0))\n",
    "        action_score = tf.convert_to_tensor(np.expand_dims(action_score, 1))\n",
    "        \n",
    "        item_idx = np.argmax(tf.keras.backend.dot(items_ebs, action_score))\n",
    "        \n",
    "        recommendation_item = int(items_ids[item_idx])\n",
    "        \n",
    "        return recommendation_item\n",
    "        \n",
    "    \n",
    "    def _reset(self):        \n",
    "        self.step_count = 1\n",
    "        self.user_id = np.random.choice(self.valid_users, size = 1).item()\n",
    "        \n",
    "        self.user_df = self.ratings_df.loc[self.ratings_df[\"UserID\"] == self.user_id]\n",
    "#         self.movie_rate_dict = defaultdict(lambda: -0.5, zip(self.user_df[\"MovieID\"], self.user_df[\"Rating\"]))\n",
    "        self.state_items_ids = self.user_df.loc[self.user_df[\"Rating\"] >= 4, \"MovieID\"].head(self.state_size).values\n",
    "        self.user_items = self.user_df[\"MovieID\"].values\n",
    "        \n",
    "        self.recommended_items = self.state_items_ids.copy()\n",
    "        \n",
    "\n",
    "        self.user_eb = self.embedding_network.get_layer('user_embedding')(np.array(self.user_id))\n",
    "        state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "        \n",
    "        \n",
    "        self.srm_ave = DRRAveStateRepresentation(self.embedding_dim)\n",
    "        self._state = self.srm_ave([np.expand_dims(self.user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)])[0]\n",
    "        \n",
    "#         for x in self.recommended_items:\n",
    "#             self.movie_rate_dict[x] = -0.5\n",
    "            \n",
    "        self._episode_ended = False\n",
    "        \n",
    "        return ts.restart(self._state)\n",
    "        \n",
    "        \n",
    "    def _generate_valid_user(self):\n",
    "        temp = self.ratings_df.loc[ratings_df[\"Rating\"] >= 4].groupby([\"UserID\"])[\"Rating\"].count()\n",
    "        valid_users = temp.loc[temp >= self.state_size].index\n",
    "        \n",
    "        return valid_users\n",
    "    \n",
    "    def _step(self, action):\n",
    "        self.step_count += 1\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return self.reset()    \n",
    "        \n",
    "        recommendation_item = self._convert_action_score_item(action)\n",
    "        self.recommendation_item = recommendation_item\n",
    "        \n",
    "        if recommendation_item in self.user_items:\n",
    "            if recommendation_item not in self.recommended_items:\n",
    "                rate = self.user_df.loc[self.user_df[\"MovieID\"] == recommendation_item, \"Rating\"].values[0]\n",
    "                reward = (rate-3)/2\n",
    "                if reward > 0:\n",
    "                    self.state_items_ids = np.append(self.state_items_ids[1:], values = recommendation_item)\n",
    "                    state_items_eb = self.embedding_network.get_layer('movie_embedding')(np.array(self.state_items_ids))\n",
    "                    self._state = self.srm_ave([np.expand_dims(self.user_eb, axis=0), np.expand_dims(state_items_eb, axis=0)])[0]\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = -0.1\n",
    "        \n",
    "        self.recommended_items = np.unique(np.append(self.recommended_items, recommendation_item))\n",
    "        \n",
    "        \n",
    "#         if len(self.recommended_items) >= 20:\n",
    "#             self._episode_ended = True\n",
    "        if self.step_count == self.max_step or len(np.setdiff1d(self.user_items, self.recommendation_item)) == 0:\n",
    "            self._episode_ended = True\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self._episode_ended:\n",
    "            return ts.termination(np.array(self._state), reward)\n",
    "        else:\n",
    "            return ts.transition(np.array(self._state), reward, discount = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continent-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_py = RS_Env(ratings_df, embedding_dim = 100, state_size = 10, embedding_network = embedding_network)\n",
    "eval_env_py = RS_Env(ratings_df, embedding_dim = 100, state_size = 10, embedding_network = embedding_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sized-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_tf = tf_py_environment.TFPyEnvironment(train_env_py)\n",
    "eval_env_tf = tf_py_environment.TFPyEnvironment(eval_env_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-print",
   "metadata": {},
   "source": [
    "### Actor Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approved-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "final-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net  = tf_agents.agents.ddpg.actor_network.ActorNetwork(\n",
    "    input_tensor_spec = train_env_tf.observation_spec(), \n",
    "    output_tensor_spec = train_env_tf.action_spec(),  # --> Only float actions are supported by this network.\n",
    "    fc_layer_params=[128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    name = \"ActorNetwork\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accepting-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = np.array(range(items_num))\n",
    "movie_embedding = embedding_network.get_layer('movie_embedding')(items_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"ActorNetwork2323\")\n",
    "\n",
    "# target_actor_net = ActorNetwork(tf_rs_env.observation_spec(), tf_rs_env.action_spec(), embedding_dim = EMBEDDING_DIM, hidden_dim = 128, items_num = items_num, movie_embedding = movie_embedding, name = \"TargetActorNetwork2323\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-friday",
   "metadata": {},
   "source": [
    "### Critic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minute-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_net = tf_agents.agents.ddpg.critic_network.CriticNetwork(\n",
    "    input_tensor_spec = (train_env_tf.observation_spec(), train_env_tf.action_spec()),\n",
    "    observation_fc_layer_params = [100],\n",
    "    joint_fc_layer_params = [128, 128],\n",
    "    activation_fn = tf.nn.relu,\n",
    "    output_activation_fn = tf.nn.relu,\n",
    "    name='CriticNetwork'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lucky-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTOR_LEARNIG_RATE = 0.001\n",
    "# CRITIC_LEARNIG_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-fruit",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "magnetic-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_agents.train.utils import train_utils\n",
    "# train_step = train_utils.create_train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "velvet-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.compat.v1.train.get_or_create_global_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "further-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ddpg_agent = tf_agents.agents.DdpgAgent(time_step_spec = train_env_tf.time_step_spec(),\n",
    "                                           action_spec = train_env_tf.action_spec(),\n",
    "                                           actor_network = actor_net,\n",
    "                                           critic_network = critic_net,\n",
    "                                           actor_optimizer = tf.keras.optimizers.Adam(learning_rate=ACTOR_LEARNIG_RATE),\n",
    "                                           critic_optimizer = tf.keras.optimizers.Adam(learning_rate=CRITIC_LEARNIG_RATE),\n",
    "#                                            target_actor_network = target_actor_net,\n",
    "#                                            target_critic_network = target_critic_net,\n",
    "                                           target_update_tau = 0.001,\n",
    "                                           target_update_period = 1,\n",
    "                                           gamma = 0.9,\n",
    "                                           ou_stddev=0.5,\n",
    "                                           ou_damping=0.15,\n",
    "                                           train_step_counter = global_step\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "proved-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ddpg_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "copyrighted-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLAY_BUFFER_MAX_LENGTH = 50000\n",
    "# NUM_EPISODE = 10000\n",
    "# BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "uniform-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: Could not serialize policy.distribution() for policy \"<tf_agents.policies.ou_noise_policy.OUNoisePolicy object at 0x7fca0c0d9400>\". Calling saved_model.distribution() will raise the following assertion error: Distributions are not implemented yet.\n"
     ]
    }
   ],
   "source": [
    "my_policy = tf_ddpg_agent.collect_policy\n",
    "saver = PolicySaver(my_policy, batch_size = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-challenge",
   "metadata": {},
   "source": [
    "### Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "parallel-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EVAL_EPISODES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sustainable-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = environment.step(action_step.action)\n",
    "        episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "beautiful-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-operations",
   "metadata": {},
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "insured-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import tf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "weekly-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPLAY_BUFFER_MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sophisticated-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the replay buffer.\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(data_spec = tf_ddpg_agent.collect_data_spec,\n",
    "                                                               batch_size = BATCH_SIZE,\n",
    "                                                               max_length = REPLAY_BUFFER_MAX_LENGTH)\n",
    "replay_observer = [replay_buffer.add_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "solid-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval_episodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unique-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_steps = tf_metrics.EnvironmentSteps(prefix='Train')\n",
    "\n",
    "average_return = tf_metrics.AverageReturnMetric(prefix='Train',\n",
    "                                                buffer_size=num_eval_episodes,\n",
    "                                                batch_size=train_env_tf.batch_size)\n",
    "\n",
    "train_metrics = [tf_metrics.NumberOfEpisodes(prefix = 'Train'),\n",
    "                 env_steps,\n",
    "                 average_return,\n",
    "                 tf_metrics.AverageEpisodeLengthMetric(prefix ='Train',\n",
    "                                                       buffer_size = num_eval_episodes,\n",
    "                                                       batch_size = train_env_tf.batch_size),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-concord",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "private-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.eval import metric_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "overall-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = greedy_policy.GreedyPolicy(tf_ddpg_agent.policy)\n",
    "\n",
    "initial_collect_policy = random_tf_policy.RandomTFPolicy(train_env_tf.time_step_spec(), train_env_tf.action_spec())\n",
    "\n",
    "collect_policy = tf_ddpg_agent.collect_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "balanced-fancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7fca0c1d05b0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_checkpointer = common.Checkpointer(ckpt_dir=os.path.join(ROOT_DIR, 'train'),\n",
    "                                         agent=tf_ddpg_agent,\n",
    "                                         global_step=global_step,\n",
    "                                         metrics=metric_utils.MetricsGroup(train_metrics, 'train_metrics'))\n",
    "\n",
    "policy_checkpointer = common.Checkpointer(ckpt_dir=os.path.join(ROOT_DIR, 'policy'),\n",
    "                                          policy=eval_policy,\n",
    "                                          global_step=global_step)\n",
    "\n",
    "rb_checkpointer = common.Checkpointer(ckpt_dir=os.path.join(ROOT_DIR, 'replay_buffer'),\n",
    "                                      max_to_keep=1,\n",
    "                                      replay_buffer=replay_buffer)\n",
    "\n",
    "train_checkpointer.initialize_or_restore()\n",
    "\n",
    "rb_checkpointer.initialize_or_restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "variable-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers import dynamic_step_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "breathing-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_steps = 100\n",
    "collect_steps_per_iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "compliant-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_collect_driver = dynamic_step_driver.DynamicStepDriver(train_env_tf,\n",
    "                                                               initial_collect_policy,\n",
    "                                                               observers=replay_observer + train_metrics,\n",
    "                                                               num_steps=initial_collect_steps)\n",
    "\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(train_env_tf,\n",
    "                                                       collect_policy,\n",
    "                                                       observers=replay_observer + train_metrics,\n",
    "                                                       num_steps=collect_steps_per_iteration)\n",
    "\n",
    "initial_collect_driver.run = common.function(initial_collect_driver.run)\n",
    "collect_driver.run = common.function(collect_driver.run)\n",
    "tf_ddpg_agent.train = common.function(tf_ddpg_agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-judges",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eleven-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "loose-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py:199: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py:199: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 1 and 32. Shapes are [1] and [32]. for '{{node driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1}} = ResourceScatterUpdate[Tindices=DT_INT64, dtype=DT_INT32](driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1/resource, driver_loop/TFUniformReplayBuffer/add, driver_loop/Placeholder_1)' with input shapes: [], [32], [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1879\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 32. Shapes are [1] and [32]. for '{{node driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1}} = ResourceScatterUpdate[Tindices=DT_INT64, dtype=DT_INT32](driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1/resource, driver_loop/TFUniformReplayBuffer/add, driver_loop/Placeholder_1)' with input shapes: [], [32], [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-bb7fd0a7afc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;34m'Initializing replay buffer by collecting experience for %d steps'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       'with a random policy.', initial_collect_steps)\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minitial_collect_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mpolicy_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mstep\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \"\"\"\n\u001b[0;32m--> 181\u001b[0;31m     return self._run_fn(\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mtime_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mpolicy_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/utils/common.py\u001b[0m in \u001b[0;36mwith_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# autodep-like behavior is already expected of fn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresource_variables_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMISSING_RESOURCE_VARIABLES_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, time_step, policy_state, maximum_iterations)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     [_, time_step, policy_state] = tf.while_loop(\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_condition_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop_body_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 602\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m   \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2532\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2727\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m   2728\u001b[0m       not executing_eagerly):\n\u001b[0;32m-> 2729\u001b[0;31m     return while_v2.while_loop(\n\u001b[0m\u001b[1;32m   2730\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloop_counter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations_arg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     body_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mbody_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mwrapped_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;31m# `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;31m# and packs it into the structure of `orig_loop_vars`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(counter, time_step, policy_state)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_time_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0mobserver_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobserver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m       transition_observer_ops = [\n\u001b[1;32m    149\u001b[0m           \u001b[0mobserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_time_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/drivers/dynamic_step_driver.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_time_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0mobserver_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobserver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_observers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m       transition_observer_ops = [\n\u001b[1;32m    149\u001b[0m           \u001b[0mobserver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_time_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/replay_buffers/replay_buffer.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mAdds\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreplay\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/replay_buffers/tf_uniform_replay_buffer.py\u001b[0m in \u001b[0;36m_add_batch\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mwrite_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_rows_for_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mwrite_id_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mwrite_data_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_id_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_data_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/replay_buffers/table.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, rows, values, slots)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mflattened_slots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mflattened_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     write_ops = [\n\u001b[0m\u001b[1;32m    129\u001b[0m         tf.compat.v1.scatter_update(self._slot2storage_map[slot], rows,\n\u001b[1;32m    130\u001b[0m                                     value).op\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tf_agents/replay_buffers/table.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mflattened_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     write_ops = [\n\u001b[0;32m--> 129\u001b[0;31m         tf.compat.v1.scatter_update(self._slot2storage_map[slot], rows,\n\u001b[0m\u001b[1;32m    130\u001b[0m                                     value).op\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_slots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36mscatter_update\u001b[0;34m(ref, indices, updates, use_locking, name)\u001b[0m\n\u001b[1;32m    302\u001b[0m     return gen_state_ops.scatter_update(ref, indices, updates,\n\u001b[1;32m    303\u001b[0m                                         use_locking=use_locking, name=name)\n\u001b[0;32m--> 304\u001b[0;31m   return ref._lazy_read(gen_resource_variable_ops.resource_scatter_update(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    305\u001b[0m       \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m       name=name))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mresource_scatter_update\u001b[0;34m(resource, indices, updates, name)\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1130\u001b[0m         \u001b[0;34m\"ResourceScatterUpdate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                                  updates=updates, name=name)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         compute_device)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3555\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2039\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1881\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 32. Shapes are [1] and [32]. for '{{node driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1}} = ResourceScatterUpdate[Tindices=DT_INT64, dtype=DT_INT32](driver_loop/TFUniformReplayBuffer/ResourceScatterUpdate_1/resource, driver_loop/TFUniformReplayBuffer/add, driver_loop/Placeholder_1)' with input shapes: [], [32], [1]."
     ]
    }
   ],
   "source": [
    "# Collect initial replay data.\n",
    "if env_steps.result() == 0 or replay_buffer.num_frames() == 0:\n",
    "    logging.info(\n",
    "      'Initializing replay buffer by collecting experience for %d steps'\n",
    "      'with a random policy.', initial_collect_steps)\n",
    "    initial_collect_driver.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-occupation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-repeat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vocal-toilet",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dense-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_episode(environment, policy, num_episodes):\n",
    "\n",
    "    episode_counter = 0\n",
    "    traj_counter = 0\n",
    "    environment.reset()\n",
    "#     print(episode_counter)\n",
    "    while episode_counter < num_episodes:\n",
    "        time_step = environment.current_time_step()\n",
    "        action_step = policy.action(time_step)\n",
    "        next_time_step = environment.step(action_step.action)\n",
    "        traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "        traj_counter += 1\n",
    "        # Add trajectory to the replay buffer\n",
    "        \n",
    "        if np.array(traj.reward)[0] != -0.1: \n",
    "            replay_buffer.add_batch(traj)           \n",
    "\n",
    "        if traj.is_boundary():\n",
    "            episode_counter += 1\n",
    "    return traj_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "stylish-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_episode(train_env_tf, tf_ddpg_agent.collect_policy, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "complete-pierce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_ddpg_agent.train = common.function(tf_ddpg_agent.train)\n",
    "tf_ddpg_agent.train_step_counter.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alert-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)\n",
    "returns = [avg_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-mercury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(NUM_EPISODE)):\n",
    "    collect_episode(train_env_tf, tf_ddpg_agent.collect_policy, 1)\n",
    "    \n",
    "#     experience = replay_buffer.as_dataset()\n",
    "    experience, unused_info = next(iterator)\n",
    "#     experience = replay_buffer.gather_all()\n",
    "    train_loss = tf_ddpg_agent.train(experience)\n",
    "#     replay_buffer.clear()\n",
    "\n",
    "    step = tf_ddpg_agent.train_step_counter.numpy()\n",
    "    \n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "        train_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env_tf, tf_ddpg_agent.policy, NUM_EVAL_EPISODES)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "according-separate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BufferInfo(ids=<tf.Tensor: shape=(32, 2), dtype=int64, numpy=\n",
       "array([[405, 406],\n",
       "       [484, 485],\n",
       "       [534, 535],\n",
       "       [525, 526],\n",
       "       [861, 862],\n",
       "       [ 15,  16],\n",
       "       [265, 266],\n",
       "       [997, 998],\n",
       "       [974, 975],\n",
       "       [459, 460],\n",
       "       [104, 105],\n",
       "       [715, 716],\n",
       "       [867, 868],\n",
       "       [901, 902],\n",
       "       [898, 899],\n",
       "       [ 87,  88],\n",
       "       [232, 233],\n",
       "       [241, 242],\n",
       "       [205, 206],\n",
       "       [876, 877],\n",
       "       [  4,   5],\n",
       "       [538, 539],\n",
       "       [899, 900],\n",
       "       [436, 437],\n",
       "       [895, 896],\n",
       "       [103, 104],\n",
       "       [159, 160],\n",
       "       [760, 761],\n",
       "       [642, 643],\n",
       "       [172, 173],\n",
       "       [245, 246],\n",
       "       [161, 162]])>, probabilities=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([0.001001, 0.001001, 0.001001, 0.001001, 0.001001, 0.001001,\n",
       "       0.001001, 0.001001, 0.001001, 0.001001, 0.001001, 0.001001,\n",
       "       0.001001, 0.001001, 0.001001, 0.001001, 0.001001, 0.001001,\n",
       "       0.001001, 0.001001, 0.001001, 0.001001, 0.001001, 0.001001,\n",
       "       0.001001, 0.001001, 0.001001, 0.001001, 0.001001, 0.001001,\n",
       "       0.001001, 0.001001], dtype=float32)>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iterator)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-character",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-rover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4796,
   "id": "attached-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
